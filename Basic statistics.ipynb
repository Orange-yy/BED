{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Basic statistics in R \n",
    "\n",
    "Here, we will work with random numbers, distributions and sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of libraries and necessary software\n",
    "\n",
    "Install the necessary libraries (only needed once) by executing (shift-enter) the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"MASS\", repos='http://cran.us.r-project.org')\n",
    "install.packages(\"cluster\", repos='http://cran.us.r-project.org')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and libraries\n",
    "This requires that the installation above have been finished without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"MASS\")\n",
    "library(\"cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "This exercise will help you to understand how probabilities are calculated. \n",
    "\n",
    "__Important:__ Take your time as several parts are tricky and quite abstract\n",
    "\n",
    "_Probabilities_\n",
    "\n",
    "1) Read the description of ```dnorm()```: ```help(dnorm)```  \n",
    "2) Plot the density (```dnorm()```) and the cumulative (```pnorm()```) probability distribution of a normal distribution with mean 2.5 and standard deviation 1.5.  \n",
    "3) Estimate the probability for getting a number between 0.5 and 4 from the figure of the cumulative distribution. Verify this number with its exact calculation ```pnorm(4, 2.5, 1.5) - pnorm(0.5, 2.5, 1.5)```  \n",
    "4) Repeat the same for the intervals (-1, 2) and (1, 2)\n",
    "\n",
    "_Frequencies_\n",
    "- The relative number of observations per unit interval around $x=2$ (number ranging from 1.5 to 2.5) is given by ```dnorm(x=2, 2.5, 1.5)```. Hence\n",
    "  - In a sample of 100 numbers taken from a normal distribution, the expected number of observations per unit interval in the immediate vicinity of $x=2$ is 25.16\n",
    "  - In a sample of 1000 numbers, the expected number of observations per unit interval in the immediate vicinity of $x=2$ is 251.6\n",
    "  - The expected number of values between 1.9 and 2.1, when having a sample taking 1000 random numbers, is approximately $0.2 \\cdot 251.6 = 50.32$, or, more precisely,\n",
    "```pnorm(2.1, 2.5, 1.5) - pnorm(1.9, 2.5, 1.5)```\n",
    "\n",
    "- Repeat the calculation for the intervals (-1,2) and (1,2). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- seq(-5,10,0.01)\n",
    "density <- dnorm(x, mean=2.5, sd=1.5)\n",
    "cumulative <- pnorm(x, mean=2.5, sd=1.5)\n",
    "\n",
    "## plot the functions:\n",
    "\n",
    "\n",
    "# This code is related to a question below and the sample with 1000 observations above\n",
    "plot(x, 1000*dnorm(x, mean=2.5, sd=1.5), type=\"l\",ylab=\"frequency\")\n",
    "interval <- seq(1.5,2.5,0.01)\n",
    "polygon(c(1.5,interval,2.5), c(0,1000*dnorm(interval, 2.5,1.5),0), col = \"#FF000055\")\n",
    "polygon(c(1.5,2.5,2.5,1.5), 1000*c(dnorm(2, 2.5,1.5),dnorm(2, 2.5,1.5),0,0), col = \"#00FF0055\")\n",
    "points(2,1000*dnorm(2,2.5,1.5),pch=15,col=2)\n",
    "text(2,1000*dnorm(2,2.5,1.5),pch=15,col=2,labels =1000*dnorm(2,2.5,1.5), pos=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>What are the 3 different arguments of these functions? How are they related to the Gaussian function?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question II:  <u>What is the difference between the first argument of ```dnorm``` and ```rnorm```?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question III:  <u>How would you estimate the probability of having a number between 0.5 and 4 from the density distribution?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question IV:  <u>What is the probability to obtain the number 2?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question V:  <u>What is the difference between probability and frequency?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question VI:  <u>How would you calculate the area of the rectangle and the area under the curve in the figure given above?</u>\n",
    "\n",
    "_Answer_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "We now check the behavior of the t-distribution which is an integral part of the t-test and the exponential function which describes many temporal processes in nature.\n",
    "\n",
    "- Plot the density and cumulative probability distribution (```dt()``` and ```pt``` with argument ```df=3```) for a t-distribution with 3 degrees of freedom. Plot the normal distribution over it with ```lines()```. \n",
    "- Plot the density and cumulative probability distribution for an exponential distribution (```dexp()```) with a rate parameter equal to 1 (the default). Repeat with a rate parameter equal to 2. What happens when you do the plot on logarithmic (y-coordinate) and double-logarithmic scale?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- seq(-5,5,0.01)\n",
    "# density function\n",
    "dens_t <- dt(x, df=3)\n",
    "\n",
    "dens_exp <- dexp(x, rate = 1)\n",
    "# continue ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>What happens with the t-distribution of high degrees of freedom?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question II:  <u>Which is a good visual way to check whether data is exponentially distributed?</u>\n",
    "\n",
    "_Answer_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "We now will generate random values and visualize them in multiple ways\n",
    "\n",
    "Use the function ```rnorm()``` to draw a random sample of 25 values from a normal distribution with a mean of 0 and a standard deviation equal to 1.0. \n",
    "\n",
    "Use a histogram, with ```probability=TRUE``` to display the values. Overlay the histogram with:  \n",
    "(a) an estimated density curve;  \n",
    "(b) the theoretical density curve for a normal distribution with mean 0 and standard deviation equal to 1.0. \n",
    "\n",
    "Repeat with samples of 100, 500 and 1000 values, showing the different displays in different panels on the same graphics page (```par(mfrow=...)```)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand <- rnorm(25)\n",
    "hist(rand, probability = TRUE,ylim=c(0,0.5), border=\"#FFFFFF\", col=\"#333333\")\n",
    "lines(density(rand))\n",
    "x <- seq(-5,5,0.01)\n",
    "lines(x, dnorm(x), col=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>What are the black and the red lines?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question II:  <u>What improves when you increase the number of values?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question III:  <u>What does ```#333333``` mean?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Data with a distribution close to lognormal are quite common. Size measurements of biological organisms often have this character. \n",
    "\n",
    "As an example, consider the measurements of body weight (```body```) in the data frame ```Animals``` (```MASS``` package). Begin by drawing a histogram of the untransformed values, and overlay a density curve. Then\n",
    "\n",
    "- Draw an estimated density curve for the logarithms of the values. \n",
    "- Determine the mean and standard deviation of ```log(Animals$body)```. Overlay the estimated density with the theoretical density for a normal distribution with the mean and standard deviation just obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,2))\n",
    "library(MASS)\n",
    "data(Animals)\n",
    "hist(Animals$body,20, probability=T)\n",
    "lines(density(Animals$body))\n",
    "dat <- log10(Animals$body)\n",
    "hist(dat,20, probability=T)\n",
    "lines(density(dat))\n",
    "hist(dat,20, probability=T)\n",
    "lines(density(dat))\n",
    "x <- seq(min(dat),max(dat),0.01)\n",
    "lines(x, dnorm(x,mean(dat),sd(dat)),col=2)\n",
    "qqnorm(dat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>Does the distribution look like a normal distribution after transformation to a logarithmic scale?</u>\n",
    "\n",
    "Difficult to determine with such a low number but it could be. The Q-Q plot is a good check for normality which is valid when the points form a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "We will now compare different types of distributions and how they look for low and high sample size.\n",
    "\n",
    "The following script plots an estimated density curve for a random sample of 50 values from a normal distribution:\n",
    "\n",
    "- Plot estimated density curves (```plot(density(...))```) for random samples containing 50 values\n",
    "  - the normal distribution\n",
    "  - the uniform distribution (```runif(50)```)\n",
    "  - the $t$-distribution with 3 degrees of freedom. \n",
    "-  Overlay the three plots and use different colors.\n",
    "- Repeat the same but now taking random samples of 500 and 5000 values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>Why is the estimated density curve of the uniformely distiubuted values much higher?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Small sample sizes with a low number of random (or measured) values are tricky to visualize as the values fluctuate a lot.\n",
    "\n",
    "There are two ways to make the estimated density smoother:\n",
    "\n",
    "- One is to increase the number of samples\n",
    "- The other is to increase the bandwidth of ```density()```. For example\n",
    "```\n",
    "plot(density(rnorm(50), bw=0.2), type=\"l\")\n",
    "plot(density(rnorm(50), bw=0.6), type=\"l\")\n",
    "```\n",
    "\n",
    "Repeat each of these with bandwidths of 0.15, with default choice of bandwidth, and with the bandwidth set to 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "The density estimation has the issue that it depends strongly on bandwidth and choice of kernel, making it sometimes not very useful to judge normality. A much better tool is the quantile-quantile plot. Try the following script and assess how the plot characterizes normally distributed data.\n",
    "- See how the plot deviates when comparing the normal distribution with random variables from other distributions.\n",
    "- Increase the number of data points\n",
    "- Substitute the ```rnorm()``` function by random variables from other distributions (e.g. ```rexp()``` and ```rlnorm()```)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqnorm(rnorm(10))\n",
    "qqnorm(rnorm(15))\n",
    "qqnorm(rnorm(200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>How does the ```qqnorm()``` function show that the data is normally distributed?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question II:  <u>Which is the limiting function when increasing the number of values to infinity?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question III:  <u>How do the other tested distributions show their difference to a normal distribution when using the ```qqnorm()``` function?</u>\n",
    "\n",
    "_Answer_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "We now will assess 2 experimental data sets for their normality.\n",
    "\n",
    "Take the data sets ```lh``` and ```Animals``` and check for normality using ```qqnorm```. Do the same on their logarithmic values. Additionally, use ```boxplot()``` to get an idea about how the boxplot of a normal distribution looks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "data(\"Animals\")\n",
    "# add your code here\n",
    "data(\"lh\")\n",
    "print(lh)\n",
    "as.data.frame(lh)\n",
    "data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>Which data set is (approximately) normally distributed?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question II:  <u>Which data set is (approximately) log-normally distributed?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "Here, we will calculate the limit distribution of the means of sets of random variables. Note that the mean corresponds to the sum divided by the number of variables, and therefore the central limit theorem applies. \n",
    "\n",
    "First take a random sample from the normal distribution, and plot the estimated density function\n",
    "\n",
    "Then, take the repeated samples of size 4, calculate the mean for each such sample, and plot the density function for the distribution of means:\n",
    "Additionally, use ```qqnorm()``` to estimate normality.\n",
    "\n",
    "Repeat this code, using different sample sizes (e.g. 9 and 25) and numbers of averages larger than 100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- rnorm(100)\n",
    "plot(density(y), type=\"l\",ylim=c(0,1))\n",
    "av <- numeric(100)\n",
    "for (i in 1:100) {\n",
    "  av[i] <- mean(rnorm(4))\n",
    "}\n",
    "lines(density(av), col=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>Why is the red distribution more narrow than the black one?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question II:  <u>What happens when increasing the sample size?</u>\n",
    "\n",
    "_Answer_\n",
    "\n",
    "##### Question III:  <u>What happens when increasing the number of averages?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "In Exercise 9, we calculated the mean of normally distributed variables. But the central limit theorem applies for almost arbitrary distributions. Show this by calculating the mean distribution of $n$ uniformly distributed variables (```runif(n)```), log-normally distributed ones (```rlnorm(n)```) and exponentially distributed ones (```rexp(n,rate=1)```) by changing the script in Exercise 9 accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>How much do you need to increase the number of samples and averages to reach a descent normal distribution (give the numbers for each type of distribution separately)?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "Instead of taking the values from a theoretical probability density function, \n",
    "it is also possible to take random samples, usually with replacement, from a vector of values that originates from an empirical distribution. This is the bootstrap concept. Again, it may of interest to study the sampling distributions of means of different sizes. Consider the distribution of heights of female Adelaide University students, in the data frame ```survey``` (_MASS_ package). The script below takes 1000 bootstrap samples of size 4, calculating the mean for each such sample.\n",
    "\n",
    "Repeat the procedure, taking samples of size 9 and 16. In each case use a density plot and ```qqnorm()``` to display the (empirical) sampling distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "y <- na.omit(survey[survey$Sex == \"Female\", \"Height\"])\n",
    "av <- numeric(1000)\n",
    "for (i in 1:1000)\n",
    "  av[i] <- mean(sample(y, 4, replace=T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>What do you observe?</u>\n",
    "\n",
    "_Answer_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "Generate random numbers from a normal distribution with a sequential dependence. The central limit theorem does not apply for variables with strong dependency. So how do we test for this dependency?\n",
    "\n",
    "Try to understand the definition of y. The autocorrelation function (```acf()``` in R) calculates the dependence within a series (see also http://en.wikipedia.org/wiki/Autocorrelation). Apply this function on both data sets and check whether there is a consistent pattern for the correlated data set. Vary number of data points and repeat the experiment several times to get feeling of how a autocorrelation function can look like. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 <- rnorm(i)\n",
    "y <- y1[-1] + y1[-i]\n",
    "acf(y1)\n",
    "acf(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>What is the main difference when introducing the above correlation?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13\n",
    "We will now visually check whether we can still observe a normal distribution as limiting distribution.\n",
    "\n",
    "See below the function that calculates the correlated data set of Exercise 12. The input of the function is the number of data points with a default value of 51. \n",
    "\n",
    "Create a ```for``` loop that calculates the sum and the mean of the correlated data set 1000 times. Check whether the sum and the mean are normally distributed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,1))\n",
    "corrdat <- function(i=51) {\n",
    "  y1 <- rnorm(i)\n",
    "  y <- y1[-1] + y1[-i]\n",
    "  return(y)\n",
    "}\n",
    "means <- sums <- vector(,1000)\n",
    "for (j in 1:1000) {\n",
    "# add our code here:\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>What do the results suggest??</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 14\n",
    "This is a simple example of how to compare a theoretical distribution with an observed one.\n",
    "\n",
    "Take the given artificial count data for e.g. the number of tumors in 7 rats suffering from a certain type of cancer.\n",
    "\n",
    "Enter the data and compute mean and variance. In order to check whether a Poisson model would be appropriate, calculate seven random values for the corresponding Poisson distribution (```lambda=78.3```). Take their mean and variance and compare them to the artificial data.\n",
    "Calculate the distribution of mean and variance, plot their histograms and check whether mean and variance from the artificial data are within the main core of the distributions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat <- c(87, 53, 72, 90, 78, 85, 83)\n",
    "rdat <- rpois(7, lambda=78.3)\n",
    "# to go on from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question I:  <u>How well does the Poisson model fit the data?</u>\n",
    "\n",
    "_Answer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
